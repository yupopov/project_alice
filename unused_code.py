def combine_features_and_split(base_features,
                               y,
                               base_feature_names, # the site names obtained by TfIdfVectorizer
                               add_features,
                               train_size):
    """Given base_features sparse matrix and add_features pandas DataFrame (with named columns),
        stack them together into a new sparse matrix, 
        collect and combine the feature names
        and split the resulting matrix into the train and validation parts."""
    if add_features is not None: # add new features if provided
        X = hstack([base_features, add_features]).tocsr() 
        feature_names = base_feature_names + list(add_features.columns)
        num_add_features = add_features.shape[1]
    else:
        X = base_features
        feature_names = base_feature_names
        num_add_features = 0
    
    train_share = int(train_size * X.shape[0]) # split the data into train and validation sets
    X_train, y_train = X[:train_share, :], y[:train_share]
    X_valid, y_valid = X[train_share:, :], y[train_share:]
    return X_train, y_train, X_valid, y_valid, feature_names, num_add_features


def select_features(feature_selector,
                   X_train,
                   y_train,
                   X_valid,
                   feature_names,
                   num_add_features,
                   verbose):
    """Given a numpy array of features X with num_additional features stacked at the end
    and a target feature vector y (already split into train and validation parts)
    with features names contained in the list feature_names,
    select the features according to some method (feature selector should implement .fit(), .get_support() 
    and .transform() methods and have .coef_ attribute, for example, sklearn's SelectFromModel or BorutaPy will do),
    save the selected feature names and transform the X_train and X_valid feature sets."""
    feature_selector.fit(X_train, y_train)
    mask = feature_selector.get_support()
        
    feature_names = np.array(feature_names)[mask].tolist() # only save the features that were selected
    if num_add_features != 0:
        num_add_features = mask[-num_add_features:].sum() # count how many additional features survived
        
    X_train = feature_selector.transform(X_train) # transform the feature sets
    X_valid = feature_selector.transform(X_valid)
    
    if verbose: # print the coefs of the additional features in the selector (if possible)
        # and number of selected features
        print(f'num of nonzero features after selection: {mask.sum()}')
        
        selector_coefs = None
        if hasattr(feature_selector, 'estimator_') and hasattr(feature_selector.estimator_, 'coef_'):
            # this option works with sklearn's SelectFromModel
            selector_coefs = feature_selector.estimator_.coef_.ravel()
        
        if selector_coefs is not None and num_add_features != 0:
            selected_add_features = pd.DataFrame({
                'feature': feature_names[-num_add_features:],
                'coef': np.abs(selector_coefs[-num_add_features:])
            })
            selected_add_features.sort_values(by='feature', ascending=False, inplace=True)
            print("Selector's coefficients of additional variables:")
            print(selected_add_features)
        
    return X_train, X_valid, feature_names, num_add_features


def cv_scheme_with_add_features(model,
                               X_train,
                               y_train,
                               X_valid,
                               y_valid,
                               feature_names,
                               num_add_features,
                               cv_split,
                               scoring,
                               metric,
                               verbose,
                               return_add_data):
    """Given a numpy array of features X and a target feature vector y
    (already split into train and validation parts) with features names contained in the list feature_names,
    the last num_add_features being additonal and of special interest
    (for example, features generated by hand as opposed to base features generated automatically),
    obtain the CV scores for a given scheme on the train part,
    then train the model on the whole train set and evaluate it on the validataion set,
    printing the weights of all features and saving the weights of additional features in a dataframe.
    The function either prints the evaluation details (verbose = True),
    or passes the additional data for further analysis (return_add_data = True)."""
    cv_scores = cross_val_score(model, X_train, y_train, scoring=scoring, cv=cv_split, n_jobs=-1)
    # calculate the CV scores for the selected scheme
    
    model.fit(X_train, y_train) # fit the model on the whole train dataset 
    if hasattr(model, 'predict_proba'): # predict on train and validation sets
      pred_on_train = model.predict_proba(X_train)[:, 1]
      pred_on_valid = model.predict_proba(X_valid)[:, 1]
    elif hasattr(model, 'decision_function'):
      pred_on_train = model.decision_function(X_train)
      pred_on_valid = model.decision_function(X_valid)
    else:
      pred_on_train = model.predict(X_train)
      pred_on_valid = model.predict(X_valid)
    
    score_on_train = metric(y_train, pred_on_train)
    score_on_valid = metric(y_valid, pred_on_valid)
    
    if num_add_features != 0:
        add_feature_names = feature_names[-num_add_features:]
        coef_attr = 'coef_' if hasattr(model, 'coef_') \
          else 'feature_importances_' if hasattr(model, 'feature_importances_') else None
        # calculate importances of additional features if they exist
        if coef_attr is not None:
          add_coefs = pd.DataFrame({
              'feature': list(add_feature_names),
              coef_attr: getattr(model, coef_attr).flatten()[-num_add_features:]
              })
          add_coefs.sort_values(by=coef_attr, ascending=False, inplace=True)
    
    if verbose: # print CV scores means, stds, feature importances of the model
        print(f'CV Scores \n {cv_scores}')
        print(f'Mean cv score: {cv_scores.mean()} \t Std cv score: {cv_scores.std()}')
        print(f'{scoring} on train: {score_on_train}') 
        print(f'{scoring} on validation: {score_on_valid}')    
        display_html(eli5.show_weights(model, feature_names=feature_names, top=30))
        if num_add_features != 0:
            print(add_coefs)
        
    if return_add_data: # return additional data which can be used for future analysis
        return [model, cv_scores, add_coefs, score_on_valid]
    return [model, cv_scores]


def cross_val_scheme(model=logit,
                     base_features=X_train_sparse,
                     base_feature_names=site_features,
                     add_features=None, # a pd.Dataframe with named columns (feature names)
                     y=targets,
                     train_size=0.9, # a float between 0 and 1
                     feature_selector=None,
                     cv_split=time_split,
                     scoring='roc_auc', 
                     metric=roc_auc_score,
                     verbose=True,
                     return_add_data=False):
    """"""
    X_train, y_train, X_valid, y_valid, feature_names, num_add_features = combine_features_and_split(
        base_features,
        y,
        base_feature_names, 
        add_features,
        train_size
    )
    
    if feature_selector is not None:
        X_train, X_valid, feature_names, num_add_features = select_features(
            feature_selector,
            X_train,
            y_train,
            X_valid,
            feature_names,
            num_add_features,
            verbose
        )

    model_and_cv_results = cv_scheme_with_add_features(
        model,
        X_train,
        y_train,
        X_valid,
        y_valid,
        feature_names,
        num_add_features,
        cv_split,
        scoring,
        metric,
        verbose,
        return_add_data
    )
    model = model_and_cv_results[0]
    
    if feature_selector is not None: # construct a pipeline from the trained feature selector and model 
        model = Pipeline(
            [('feature_selector', feature_selector),
             ('classifier', model)]
        )
        model_and_cv_results[0] = model

    return model_and_cv_results

def highest_weight_cutoff(features_coefs):
    """Given a DataFrame of n features (not a big number)
    that has two columns with feature names and feature weights (evaluated on some model),
    yield only the names of k features with the highest absolute weight, for k = 1, ..., n."""
    num_features = features_coefs.shape[0]
    features_coefs.coef = np.abs(features_coefs.coef)
    features_coefs.sort_values(by='coef', ascending=False, inplace=True)
    best_features = features_coefs.feature
    
    for k in range(1, num_features + 1):
        k_best_features = list(best_features[:k])
        yield k_best_features
        

def mutual_info_cutoff(features, y):
    """Given a DataFrame of n features (not a big number), evaluate mutual information of each feature
    with the target feature y and yield only the names of k features with the best mutual information,
    for k = 1, ..., n."""
    num_features = features.shape[1]
    mutual_info = pd.DataFrame({
        'feature': list(add_train_df.columns),
        'mutual_info_with_target': mutual_info_classif(add_train_df, y)
    })
    mutual_info.sort_values(by='mutual_info_with_target', ascending=False, inplace=True)
    best_features = mutual_info.feature
    
    for k in range(1, num_features + 1):
        k_best_features = list(best_features[:k])
        yield k_best_features



def subset_performance(add_features_subsets, # a generator that yields subsets of feature names
                       *args, # the rest of the signature coincides with cross_val_scheme
                       add_features=add_train_df,
                       save_subset=False,
                       **kwargs
                      ):
    """Given a generator add_features_subsets that yields subsets of names of additional features
    (generally a chain of subsets), for each subset M calculate the model performance
    (size of M, CV mean, CV std, final score on validation set)
    on the set (base features + M) using the function cross_val_score.
    Return a dataframe containing sizes of M and the model performances"""
    subset_scores = []
    for subset in tqdm_notebook(add_features_subsets):
        _, cv_scores, _, final_score = cross_val_scheme(
            *args,
            add_features=add_features[subset], # only add the selected additional features
            verbose=False,
            return_add_data=True,
            **kwargs
        )
        subset_data = [
             len(subset),
             cv_scores.mean(),
             cv_scores.std(),
             cv_scores.mean() - cv_scores.std(),
             final_score
        ]
        if save_subset:
            subset_data.append(subset)
        subset_scores.append(subset_data)

    columns=[
        'num_add_features',
        'cv_mean',
        'cv_std',
        'cv_mean-cv_std',
        'scoring_on_valid'
    ]    
    if save_subset:
        columns.append('subset')
    subset_scores = pd.DataFrame(subset_scores, columns=columns)
    subset_scores.sort_values(by='cv_mean-cv_std', ascending=False, inplace=True)
    return subset_scores




